{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('tf_gpu': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6f5c13d7f067e07ac07ccae550306967bc68d11f430dbcf31219d8e25bd497c1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.3.0-py3-none-any.whl (981 kB)\n",
      "\u001b[K     |████████████████████████████████| 981 kB 474 kB/s \n",
      "\u001b[?25hCollecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n",
      "\u001b[K     |████████████████████████████████| 358 kB 1.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: urllib3[secure,socks]~=1.26 in /home/tahooramajlesi/anaconda3/envs/tf_gpu/lib/python3.8/site-packages (from selenium) (1.26.3)\n",
      "Requirement already satisfied: sortedcontainers in /home/tahooramajlesi/anaconda3/envs/tf_gpu/lib/python3.8/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/tahooramajlesi/anaconda3/envs/tf_gpu/lib/python3.8/site-packages (from trio~=0.17->selenium) (20.3.0)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: async-generator>=1.9 in /home/tahooramajlesi/anaconda3/envs/tf_gpu/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Collecting sniffio\n",
      "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: idna in /home/tahooramajlesi/anaconda3/envs/tf_gpu/lib/python3.8/site-packages (from trio~=0.17->selenium) (2.10)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in /home/tahooramajlesi/anaconda3/envs/tf_gpu/lib/python3.8/site-packages (from urllib3[secure,socks]~=1.26->selenium) (20.0.1)\n",
      "Requirement already satisfied: certifi in /home/tahooramajlesi/anaconda3/envs/tf_gpu/lib/python3.8/site-packages (from urllib3[secure,socks]~=1.26->selenium) (2019.11.28)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in /home/tahooramajlesi/anaconda3/envs/tf_gpu/lib/python3.8/site-packages (from urllib3[secure,socks]~=1.26->selenium) (3.3.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /home/tahooramajlesi/anaconda3/envs/tf_gpu/lib/python3.8/site-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: six>=1.4.1 in /home/tahooramajlesi/anaconda3/envs/tf_gpu/lib/python3.8/site-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/tahooramajlesi/anaconda3/envs/tf_gpu/lib/python3.8/site-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /home/tahooramajlesi/anaconda3/envs/tf_gpu/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.20)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 1.2 MB/s \n",
      "\u001b[?25hInstalling collected packages: sniffio, outcome, h11, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed h11-0.13.0 outcome-1.2.0 selenium-4.3.0 sniffio-1.2.0 trio-0.21.0 trio-websocket-0.9.2 wsproto-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, sys, time\n",
    "from urllib.parse import urlparse\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from sqlite_linkedin import insert_general_info, insert_educated, insert_education, insert_experience, insert_experienced, insert_license, insert_licensed\n",
    "from selenium.webdriver.common.by import By\n",
    "import sqlite3\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "from selenium.webdriver.common.by import By\n",
    "from sqlite_linkedin import insert_general_info, insert_educated, insert_education, insert_experience, insert_experienced, insert_license, insert_licensed\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from urllib.parse import urlparse\n",
    "import logging\n"
   ]
  },
  {
   "source": [
    "# setting logging"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.basicConfig(level=logging.INFO, filename=\"linkedin.log\",\n",
    "                    filemode=\"w\", format=\"%(message)s\")\n",
    "\n",
    "logging.info(\"start\")\n",
    "\n",
    "visitedProfiles = []\n",
    "profilesQueued = []\n"
   ]
  },
  {
   "source": [
    "# Logging to LinkedIn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('driver/chromedriver')\n",
    "driver.get('https://www.linkedin.com/login')\n",
    "file = open('config.txt')\n",
    "lines = file.readlines()\n",
    "\n",
    "username = lines[0]\n",
    "password = lines[1]\n",
    "\n",
    "elementID = driver.find_element(By.ID, 'username')\n",
    "elementID.send_keys(username)\n",
    "\n",
    "elementID = driver.find_element(By.ID, 'password')\n",
    "elementID.send_keys(password)\n",
    "\n",
    "elementID.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"logged into linkedin\")"
   ]
  },
  {
   "source": [
    "# download the required version of webdriver and use the command : \n",
    "driver = webdriver.Chrome(\"path of webdriver\")\n",
    "# or use this command to automatically download\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrolling_down():\n",
    "    SCROLL_PAUSE_TIME = 2\n",
    "\n",
    "    # Get scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        # Scroll down to bottom\n",
    "        driver.execute_script(\n",
    "            \"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # Wait to load page\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            try:\n",
    "                button_show_more = driver.find_element(\n",
    "                    By.XPATH, \"//button[@aria-label='Show more results']\")\n",
    "                button_show_more.click()\n",
    "                last_height = new_height\n",
    "            except:\n",
    "                break\n",
    "                # break\n",
    "        last_height = new_height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNewProfileIDS(soup, profilesQueued):\n",
    "    profilesId = []\n",
    "    pav = soup.find('section', {'class':\"artdeco-card ember-view mn-connections mb4\"})\n",
    "    all_links = pav.findAll('a', {'class': 'ember-view mn-connection-card__picture'})\n",
    "    for link in all_links:\n",
    "        userID = link.get('href')\n",
    "        if ((userID not in profilesQueued) and (userID not in visitedProfiles)):\n",
    "            profilesId.append(userID)\n",
    "    return profilesId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_all_connections():\n",
    "    driver.get(\"https://www.linkedin.com/mynetwork/invite-connect/connections/\")\n",
    "\n",
    "    scrolling_down()\n",
    "    driver.execute_script(\"window.scrollTo(0, -5);\")\n",
    "    scrolling_down()\n",
    "\n",
    "    \n",
    "\n",
    "    src = driver.page_source\n",
    "    soup = BeautifulSoup(src, 'lxml')\n",
    "\n",
    "    profiles = getNewProfileIDS(BeautifulSoup(driver.page_source), profilesQueued)\n",
    "    return profiles \n",
    "\n"
   ]
  },
  {
   "source": [
    "# Getting all connections id"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There is about 1338 connections\n"
     ]
    }
   ],
   "source": [
    "profilesQueued = getting_all_connections()\n",
    "print(f\"There is about {len(profilesQueued)} connections\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_general_info(soup):\n",
    "    name_div = soup.find('div', {'class': 'mt2 relative'})\n",
    "    name_family = name_div.find('h1').get_text().strip()\n",
    "    location = soup.find('span', {'class': 'text-body-small inline t-black--light break-words'}).get_text().strip()\n",
    "    profile_title = soup.find('div', {'class': 'text-body-medium break-words'}).get_text().strip()\n",
    "    logging.info(f\"{[name_family, profile_title, location]}\")\n",
    "    return insert_general_info(conn, c, [name_family, profile_title, location])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_total_experience_part(parts):\n",
    "    for i in range(len(parts)):\n",
    "        if parts[i].find(id=\"experience\")!=None:\n",
    "            experience_lists = parts[i].find_all('li', {'class':'artdeco-list__item pvs-list__item--line-separated pvs-list__item--one-column'})\n",
    "            return experience_lists\n",
    "\n",
    "\n",
    "def getting_details_experience(experience_list_div):\n",
    "    detail = experience_list_div.find(\"div\", {'class': 'display-flex align-items-center'})\n",
    "\n",
    "    occupation_type = detail.find('span').find('span').get_text().strip()\n",
    "\n",
    "    occupation_comp = experience_list_div.find_all('span', {'class': 't-14 t-normal'})[0].find('span').get_text().strip()\n",
    "\n",
    "    occupation_div = experience_list_div.find('span', {'class': 't-14 t-normal t-black--light'})\n",
    "    occupation_duration = \"\" if occupation_div==None else occupation_div.find('span').get_text().strip()\n",
    "    logging.info(f\"{[occupation_type, occupation_comp, occupation_duration]}\")\n",
    "    return insert_experience(conn, c, [occupation_type, occupation_comp, occupation_duration])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_total_education_part(parts):\n",
    "    for i in range(len(parts)):\n",
    "        if parts[i].find(id=\"education\")!=None:\n",
    "            education_lists = parts[i].find_all('li', {'class': 'artdeco-list__item pvs-list__item--line-separated pvs-list__item--one-column'})\n",
    "            return education_lists\n",
    "\n",
    "\n",
    "def getting_details_education(education_list_div):\n",
    "    detail = education_list_div.find(\"div\", {'class': 'display-flex align-items-center'})\n",
    "\n",
    "    institution = detail.find('span').find('span').get_text().strip()\n",
    "\n",
    "    major_div = education_list_div.find_all('span', {'class': 't-14 t-normal'})\n",
    "    major = \"\" if major_div==[] else major_div[0].find('span').get_text().strip()\n",
    "    \n",
    "    \n",
    "    duration_div = education_list_div.find('span', {'class': 't-14 t-normal t-black--light'})\n",
    "    education_duration = \"\" if duration_div==None else duration_div.find('span').get_text().strip() \n",
    "    logging.info(f\"{[institution, major, education_duration]}\")\n",
    "    return insert_education(conn, c, [institution, major, education_duration])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_total_licenses_part(parts):\n",
    "    for i in range(len(parts)):\n",
    "        if parts[i].find(id=\"licenses_and_certifications\")!=None:\n",
    "            license_lists = parts[i].find_all('li', {'class':'artdeco-list__item pvs-list__item--line-separated pvs-list__item--one-column'})\n",
    "            return license_lists\n",
    "\n",
    "def getting_details_license(license_list_div):\n",
    "    detail = license_list_div.find(\"div\", {'class': 'display-flex align-items-center'})\n",
    "\n",
    "    title = detail.find('span').find('span').get_text().strip()\n",
    "\n",
    "    institution = license_list_div.find_all('span', {'class': 't-14 t-normal'})[0].find('span').get_text().strip()\n",
    "    logging.info(f\"{[title, institution]}\")\n",
    "    return insert_license(conn, c,[title, institution])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_insert_info(conn, c,soup):\n",
    "    person_id = getting_general_info(soup)\n",
    "    parts = soup.find_all('section', {'class': 'artdeco-card ember-view relative break-words pb3 mt2'})\n",
    "\n",
    "\n",
    "    experiences_div = getting_total_experience_part(parts)\n",
    "    if experiences_div != None:\n",
    "        for exp in experiences_div:\n",
    "            exp_id = getting_details_experience(exp)\n",
    "            insert_experienced(conn, c, person_id, exp_id) \n",
    "        #map(lambda exp: insert_experienced(person_id, getting_details_experience(exp)), experiences_div)\n",
    "\n",
    "    education_div = getting_total_education_part(parts)\n",
    "    if education_div!=None:\n",
    "        for edu in education_div:\n",
    "            edu_id = getting_details_education(edu)\n",
    "            insert_educated(conn, c, person_id, edu_id)\n",
    "        #map(lambda edu: insert_educated(person_id, getting_details_education(edu)), education_div)\n",
    "\n",
    "    licenses_div = getting_total_licenses_part(parts)\n",
    "    if licenses_div!=None:\n",
    "        for lic in licenses_div:\n",
    "            license_id = getting_details_license(lic)\n",
    "            insert_licensed(conn, c, person_id, license_id)\n",
    "        #map(lambda lic: insert_licensed(person_id, getting_details_license(lic)), licenses_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_id = 0\n",
    "profilesQueued.append('/in/tahoora-majlesi/')\n"
   ]
  },
  {
   "source": [
    "# Connecting to sqlite db"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7fd56a921810>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('linkedin.db')\n",
    "\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute(\"\"\" CREATE TABLE IF NOT EXISTS generalInfo (\n",
    "                id integer PRIMARY KEY AUTOINCREMENT,\n",
    "                name text NOT NULL,\n",
    "                profession text,\n",
    "                location text\n",
    "            ); \"\"\")\n",
    "\n",
    "\n",
    "c.execute(\"\"\" CREATE TABLE IF NOT EXISTS experience (\n",
    "                id integer PRIMARY KEY AUTOINCREMENT,\n",
    "                position text NOT NULL,\n",
    "                company text,\n",
    "                duration text\n",
    "            ); \"\"\")\n",
    "\n",
    "\n",
    "c.execute(\"\"\" CREATE TABLE IF NOT EXISTS education (\n",
    "                id integer PRIMARY KEY AUTOINCREMENT,\n",
    "                title text NOT NULL,\n",
    "                institution text,\n",
    "                duration text\n",
    "            ); \"\"\")\n",
    "\n",
    "c.execute(\"\"\" CREATE TABLE IF NOT EXISTS license (\n",
    "                id integer PRIMARY KEY AUTOINCREMENT,\n",
    "                title text NOT NULL,\n",
    "                institution text\n",
    "            ); \"\"\")\n",
    "\n",
    "c.execute(\"\"\" CREATE TABLE IF NOT EXISTS educated (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                person_id INTEGER,\n",
    "                education_id INTEGER,\n",
    "                FOREIGN KEY(person_id) REFERENCES generalInfo(id),\n",
    "                FOREIGN KEY(education_id) REFERENCES education(id)\n",
    "            ); \"\"\")\n",
    "\n",
    "\n",
    "c.execute(\"\"\" CREATE TABLE IF NOT EXISTS experienced (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                person_id INTEGER,\n",
    "                experience_id ,\n",
    "                FOREIGN KEY(person_id) REFERENCES generalInfo (id),\n",
    "                FOREIGN KEY(experience_id) REFERENCES experience(id)\n",
    "            ); \"\"\")\n",
    "\n",
    "c.execute(\"\"\" CREATE TABLE IF NOT EXISTS licensed (\n",
    "                id integer PRIMARY KEY AUTOINCREMENT,\n",
    "                person_id INTEGER,\n",
    "                license_id INTEGER,\n",
    "                FOREIGN KEY(person_id) REFERENCES generalInfo(id),\n",
    "                FOREIGN KEY(license_id) REFERENCES licence(id)\n",
    "            ); \"\"\")"
   ]
  },
  {
   "source": [
    "# Inserting all connections info"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/in/mohammad-hossein-jamaati/\n",
      "=================================\n",
      "/in/fateme-pourrahimi-a88622192/\n",
      "=================================\n",
      "/in/mahkame-arabgari/\n",
      "=================================\n",
      "/in/shiralizadeh/\n",
      "=================================\n",
      "/in/amirhasan-sadatmand-137394174/\n",
      "=================================\n",
      "/in/aliardestani021/\n",
      "=================================\n",
      "/in/amir-hajizadeh/\n",
      "=================================\n",
      "/in/alierashidi-bs/\n",
      "=================================\n",
      "/in/mahdi-heidari-196303222/\n",
      "=================================\n",
      "/in/mohammad-hassannejadi/\n",
      "=================================\n",
      "/in/vahid-ilkhani-zadeh-7bb67175/\n",
      "=================================\n",
      "/in/m-hejrati/\n",
      "=================================\n",
      "/in/morteza-shahrabi-farahani-70b618201/\n",
      "=================================\n",
      "/in/peymanabbasi/\n",
      "=================================\n",
      "/in/mahdi-mallaki-1aa9b083/\n",
      "=================================\n",
      "/in/faezeh-ghorbannezhad-27121249/\n",
      "=================================\n",
      "/in/sina-shariati-817699156/\n",
      "=================================\n",
      "/in/pouria-jahandideh-879040157/\n",
      "=================================\n",
      "/in/aylarsedaei/\n",
      "=================================\n",
      "/in/behdad-mansouri-36637715a/\n",
      "=================================\n",
      "/in/mohsen-delavari-13643479/\n",
      "=================================\n",
      "/in/amirreza-naziri/\n",
      "=================================\n",
      "/in/nasser-niazy/\n",
      "=================================\n",
      "/in/rojinakashefi/\n",
      "=================================\n",
      "/in/saeed-aliverdikhani/\n",
      "=================================\n",
      "/in/raha-ahmadi-12b4631b4/\n",
      "=================================\n",
      "/in/mohammadali-esfahani/\n",
      "=================================\n",
      "/in/nima-ferdosi-8156b076/\n",
      "=================================\n",
      "/in/aldo-lipani/\n",
      "=================================\n",
      "/in/emahdimohammadi/\n",
      "=================================\n",
      "/in/hiresh-mohammadi-1793b222a/\n",
      "=================================\n",
      "/in/dylan-darby/\n",
      "=================================\n",
      "/in/hossein-asadi-769583209/\n",
      "=================================\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7c1bd5f8107f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mget_insert_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-a8e0a31a3cc1>\u001b[0m in \u001b[0;36mget_insert_info\u001b[0;34m(conn, c, soup)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexperiences_div\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexperiences_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mexp_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetting_details_experience\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0minsert_experienced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperson_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#map(lambda exp: insert_experienced(person_id, getting_details_experience(exp)), experiences_div)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-8de36c0306ec>\u001b[0m in \u001b[0;36mgetting_details_experience\u001b[0;34m(experience_list_div)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0moccupation_comp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperience_list_div\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m't-14 t-normal'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0moccupation_duration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperience_list_div\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m't-14 t-normal t-black--light'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{[occupation_type, occupation_comp, occupation_duration]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minsert_experience\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moccupation_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moccupation_comp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moccupation_duration\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "person_id = 0\n",
    "for prof in profilesQueued:\n",
    "    fullLink = \"https://www.linkedin.com\"+prof\n",
    "    print(prof)\n",
    "    print(\"=================================\")\n",
    "    driver.get(fullLink)\n",
    "\n",
    "    scrolling_down()\n",
    "\n",
    "    src = driver.page_source\n",
    "    soup = BeautifulSoup(src, 'lxml')\n",
    "    get_insert_info(conn, c,soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}